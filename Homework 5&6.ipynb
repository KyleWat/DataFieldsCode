{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "  span.ecb { background: yellow; }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style type=\"text/css\">\n",
    "  span.ecb { background: yellow; }\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from functools import partial\n",
    "from scipy.spatial import cKDTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ATMO 5331 - Homework 5 & 6 - Fall 2023\n",
    "## Due **Thursday** 30 Nov, 2023, 11:59 pm.\n",
    "## *Worth two assignments*\n",
    "\n",
    "When doing this homework, remember that you have two jobs:\n",
    "1. Make it work.\n",
    "2. Clean it up so that I can understand what you've done. If you think I might not understand, document it with a comment or a function docstring.\n",
    "\n",
    "You should present your work with a clear logical progression. If that seems like a hassle, remember that in doing so you are practicing skills that are expected in your thesis and journal publications.\n",
    "\n",
    "You may work alone or in pairs. I will not be adjudicating relative level of effort in group work, so you are responsible for ensuring that you and your partner contribute equally.\n",
    "\n",
    "<span class=\"ecb\">Comments by ECB</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.** Copy in your setup from HW3, so that you have the radar data, radar locations, and analysis grid available. Use only the tangent plane cartesian system part, and you don't need to include the plots. Take the time to clean up your original code so that it's the minimally necessary set of variables and functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585\n",
      "585\n",
      "585\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "scan_idx = 1\n",
    "\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "\n",
    "d = xr.open_dataset('Ka2140614021408.RAWPXA9.nc')\n",
    "\n",
    "az = d.azimuth[:]\n",
    "el = d.elevation[:]\n",
    "t = d.time[:]\n",
    "\n",
    "def centers_to_edges_1d(x):\n",
    "    nx_edges = x.shape[0]+1\n",
    "    xe = np.zeros(nx_edges)\n",
    "    # Fill in the middle of the grid with average poitions\n",
    "    xe[1:-1] = (x[1:] + x[:-1])/2.0\n",
    "    # For the outermost points, use half the spacing of the center points closest to each end\n",
    "    xe[0] = x[0] - (x[1] - x[0])/2.0\n",
    "    xe[-1] = x[-1] + (x[-1] - x[-2])/2.0\n",
    "    return xe\n",
    "\n",
    "def spherical_coord_edges(d, scan_idx):\n",
    "    start = d.sweep_start_ray_index[scan_idx].data\n",
    "    stop = d.sweep_end_ray_index[scan_idx].data\n",
    "    print(stop-start)\n",
    "    r = d.range[:]\n",
    "    r = centers_to_edges_1d(r.data)\n",
    "    az = d.azimuth[start:stop]\n",
    "    az = centers_to_edges_1d(az.data)\n",
    "    el = d.elevation[start:stop]\n",
    "    el = centers_to_edges_1d(el.data)\n",
    "    return(r,az,el)\n",
    "    \n",
    "def coords_2d(d, scan_idx):\n",
    "    r,az,el = spherical_coord_edges(d, scan_idx)\n",
    "    r2D,az2d = np.meshgrid(r,az)\n",
    "    r2D,el2d = np.meshgrid(r,el)   \n",
    "    return(r2D, az2d, el2d)\n",
    "\n",
    "r, az, el = coords_2d(d, scan_idx)\n",
    "\n",
    "from coords import TangentPlaneCartesianSystem\n",
    "from coords import RadarCoordinateSystem\n",
    "r, az, el = coords_2d(d, scan_idx)\n",
    "\n",
    "start = d.sweep_start_ray_index[scan_idx].data\n",
    "stop = d.sweep_end_ray_index[scan_idx].data\n",
    "ref = d.reflectivity[start:stop,:].data\n",
    "velo = d.velocity[start:stop,:].data\n",
    "SWidth = d.spectrum_width[start:stop,:].data\n",
    "Power = d.normalized_coherent_power[start:stop,:].data\n",
    "\n",
    "RadarObject = RadarCoordinateSystem(ctrLat = d.latitude.data,ctrLon = d.longitude.data, ctrAlt = d.altitude.data)\n",
    "TPlane = TangentPlaneCartesianSystem(ctrLat = d.latitude.data,ctrLon = d.longitude.data, ctrAlt = d.altitude.data)\n",
    "RadarX,RadarY,RadarZ = RadarObject.toECEF(r,az,el)\n",
    "x,y,z = TPlane.fromECEF(RadarX,RadarY,RadarZ)\n",
    "x.shape = r.shape\n",
    "y.shape = r.shape\n",
    "z.shape = r.shape\n",
    "\n",
    "startrange = 9000\n",
    "stoprange = 9505\n",
    "steprange = 5\n",
    "\n",
    "startalt = 2900\n",
    "stopalt = 3405\n",
    "stepalt = 5\n",
    "rangearray = np.arange(startrange, stoprange, steprange)\n",
    "altarray = np.arange(startalt, stopalt, steprange)\n",
    "\n",
    "\n",
    "rangearray2D = centers_to_edges_1d(rangearray)\n",
    "altarray2D = centers_to_edges_1d(altarray)\n",
    "\n",
    "rangearray2D = rangearray2D[1:-1]\n",
    "altarray2D = altarray2D[1:-1]\n",
    "\n",
    "rangearray2D, altarray2D = np.meshgrid(rangearray2D, altarray2D)\n",
    "\n",
    "from metpy.interpolate import interpolate_to_points\n",
    "d = xr.open_dataset('Ka2140614021408.RAWPXA9.nc')\n",
    "\n",
    "def spherical_coord_edges_fake(d, scan_idx):\n",
    "    start = d.sweep_start_ray_index[scan_idx].data\n",
    "    stop = d.sweep_end_ray_index[scan_idx].data\n",
    "    print(stop-start)\n",
    "    r = d.range[:]\n",
    "    az = d.azimuth[start:stop]\n",
    "    el = d.elevation[start:stop]\n",
    "    return(r,az,el)\n",
    "    \n",
    "def coords_2d2(d, scan_idx):\n",
    "    r,az,el = spherical_coord_edges_fake(d, scan_idx)\n",
    "    r2D,az2d = np.meshgrid(r,az)\n",
    "    r2D,el2d = np.meshgrid(r,el)   \n",
    "    return(r2D, az2d, el2d)\n",
    "\n",
    "r2D, az2D, el2D = coords_2d2(d, scan_idx)\n",
    "\n",
    "start = d.sweep_start_ray_index[scan_idx].data\n",
    "stop = d.sweep_end_ray_index[scan_idx].data\n",
    "ref = d.reflectivity[start:stop,:].data\n",
    "velo = d.velocity[start:stop,:].data\n",
    "SWidth = d.spectrum_width[start:stop,:].data\n",
    "Power = d.normalized_coherent_power[start:stop,:].data\n",
    "RadarObject = RadarCoordinateSystem(ctrLat = d.latitude.data,ctrLon = d.longitude.data, ctrAlt = d.altitude.data)\n",
    "TPlane = TangentPlaneCartesianSystem(ctrLat = d.latitude.data,ctrLon = d.longitude.data, ctrAlt = d.altitude.data)\n",
    "RadarX,RadarY,RadarZ = RadarObject.toECEF(r2D,az2D,el2D)\n",
    "xnew,ynew,znew = TPlane.fromECEF(RadarX,RadarY,RadarZ)\n",
    "x2D = xnew.flatten()\n",
    "z2D = znew.flatten()\n",
    "\n",
    "range2D = rangearray2D.flatten()\n",
    "alt2D = altarray2D.flatten()\n",
    "\n",
    "xnew = xnew.reshape(r2D.shape)\n",
    "ynew = ynew.reshape(r2D.shape)\n",
    "znew = znew.reshape(r2D.shape)\n",
    "\n",
    "refflat = ref.flatten()\n",
    "veloflat = velo.flatten()\n",
    "SWidthflat = SWidth.flatten()\n",
    "Powerflat = Power.flatten()\n",
    "\n",
    "TrueSpot1 = (x2D >= 9000) & (x2D<= 9500)\n",
    "TrueSpot2 = (z2D >= 2900) & (z2D<= 3400)\n",
    "TrueSpot = TrueSpot1 & TrueSpot2\n",
    "refTrue = refflat[TrueSpot]\n",
    "veloTrue = veloflat[TrueSpot]\n",
    "SWidthTrue = SWidthflat[TrueSpot]\n",
    "PowerTrue = Powerflat[TrueSpot]\n",
    "x2D = x2D[TrueSpot]\n",
    "z2D = z2D[TrueSpot]\n",
    "\n",
    "theStack = (np.vstack((x2D,z2D))).T\n",
    "theStack2 = (np.vstack((range2D, alt2D))).T\n",
    "\n",
    "refinterpLinear = interpolate_to_points(theStack, refTrue, theStack2, interp_type = 'linear')\n",
    "refinterpNearestNeighbor = interpolate_to_points(theStack, refTrue, theStack2, interp_type = 'nearest')\n",
    "refinterpBarnes = interpolate_to_points(theStack, refTrue, theStack2, interp_type = 'barnes')\n",
    "\n",
    "rangenew = ((xnew**2)+(ynew**2))**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.** Configuration of the weighting scheme requires that we know the typical data spacing. Following [TD2000](https://journals.ametsoc.org/view/journals/atot/17/2/1520-0426_2000_017_0105_rdoa_2_0_co_2.xml?tab_body=fulltext-display), define the data spacing as the distance betweent two radar gates at the maximum range. Use the point in your analysis grid that is farthest from the radar, and then find the maximum spacing in elevation angle at this range. Finally, calculate the difference in linear units between the two radar gates you idenified.\n",
    "\n",
    "Please provide an answer to these two questions:\n",
    "- What is the maximum distance from the radar in the objective analysis domain?\n",
    "- What is the maximum spacing between two adjacent data points?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xNewDelta = xnew - 9500\n",
    "zNewDelta = znew - 3400\n",
    "rNewDelta = ((xNewDelta**2)+(zNewDelta**2))**0.5\n",
    "rmaxindex = np.unravel_index(np.argmin(rNewDelta),rNewDelta.shape)\n",
    "# Convert tuple to list, subtract 1, and convert back to tuple\n",
    "rmaxindex = tuple(x - 1 for x in rmaxindex)\n",
    "\n",
    "farthestDifference = ((xnew[rmaxindex]**2)+(znew[rmaxindex]**2))**0.5\n",
    "print(\"The farthest distance in our analysis domain is: \", farthestDifference,\"m\")\n",
    "\n",
    "def calculate_column_differences(matrix, column_number):\n",
    "    differences = []\n",
    "    for i in range(1, len(matrix)):\n",
    "        diff = matrix[i][column_number] - matrix[i - 1][column_number]\n",
    "        differences.append(diff)\n",
    "    return differences\n",
    "print(rangenew.shape\n",
    "     )\n",
    "deltaArray = calculate_column_differences(el,rmaxindex[0])\n",
    "elMaxIndex = np.argmax(deltaArray)\n",
    "rangeDifference = abs(rangenew[rmaxindex[0],elMaxIndex] - rangenew[rmaxindex[0]-1,elMaxIndex-1])\n",
    "elDifference = abs(znew[rmaxindex[0],elMaxIndex] - znew[rmaxindex[0]-1,elMaxIndex-1])\n",
    "endDifference = ((rangeDifference**2) +(elDifference**2))**0.5\n",
    "print(\"The farthest distance between points in our analysis domain is: \", endDifference,\"m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.** Below, the function `oban` (for \"objective analysis\") mimics the call signature of the MetPy `interpolate_to_points` function. Its principal difference is the `weight_func` argument, which takes a function instead of a string describing an interpolation method. \n",
    "\n",
    "The `oban` function passes `weight_func` only the distances, so it is necessary to use `partial` to pre-fill the function with any other arguments needed to configure the weight function. The `sample_weights` function below shows how this works.\n",
    "\n",
    "For fun, I've also included a seasonal illustration of the use of `partial`.\n",
    "\n",
    "For this question, your jobs are as follows.\n",
    "\n",
    "**a.**  Specify a cutoff radius. Based on the last homework assignment, what is a good distance to use as a multiple of the data spacing? Make sure to adjust your set of input data points to include the necessary margin beyond the perimeter of the analysis grid.\n",
    "\n",
    "**b.**  Implement a `barnes` function and then use it with `oban` to calculate an analysis for reflectivity on the target grid.  Note that you will need to complete the `oban` function in a way that will work with any weight function.\n",
    "\n",
    "**c.**  Calculate a Barnes analysis using MetPy, as in the last assignment, and find the difference (yours - MetPy). They probably won't be the same, even for a sane configuration of parameters; that's ok.\n",
    "\n",
    "**d.**  Plot the original data, the two analyses, and the difference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "points = theStack\n",
    "\n",
    "xi = theStack2\n",
    "reflat = refTrue\n",
    "delta = endDifference\n",
    "search_radius = 3*delta\n",
    "Ln = 2 * delta\n",
    "fs = (1/delta)\n",
    "fn = fs/2\n",
    "kstar = 0.5\n",
    "k = kstar*(Ln**2)\n",
    "\n",
    "def oban(points, values, xi, weight_func, search_radius):\n",
    "    \"\"\"\n",
    "    points: N,2 data point locations\n",
    "    values: N data values\n",
    "    xi: M,2 analysis locations\n",
    "    weight_func is a function that accepts a single argument r that is the\n",
    "        distance between the analysis location and all points within search_radius\n",
    "        of the analysis location.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Find all points in the vicinity of each analysis location in xi\n",
    "    tree = cKDTree(points)\n",
    "    query = tree.query_ball_point(xi, search_radius)\n",
    "    analysis = np.zeros(xi.shape[0])\n",
    "    \n",
    "    # This is linear (times the typical neighborhood size) in the number of analysis points\n",
    "    for i, (analysis_point, neighbors) in enumerate(zip(xi, query)):\n",
    "\n",
    "        data = values[neighbors]\n",
    "        data_locations = points[neighbors,:]\n",
    "        data_locations_x = data_locations[:,0]\n",
    "        data_locations_z = data_locations[:,1]\n",
    "        delta_locations_x = data_locations_x - analysis_point[0]\n",
    "        delta_locations_z = data_locations_z - analysis_point[1]\n",
    "        delta_locations_r = ((delta_locations_x**2)+(delta_locations_z**2))**0.5\n",
    "        weight = weight_func(delta_locations_r)\n",
    "        normal_weight = weight/(np.sum(weight))\n",
    "        # use data, data_locations, analysis_point, and weight_func to fill in the rest of the analysis\n",
    "        analysis[i] = np.sum(normal_weight*data)\n",
    "    return analysis, weight\n",
    "\n",
    "def barnes(r, k):\n",
    "    \"\"\" r has units of distance, and k is the dimensional weight parameter kappa\n",
    "        kappa with units of distance squared.\n",
    "        \n",
    "        Returns the weights as a funcion of r.\n",
    "    \"\"\"\n",
    "    w = np.exp((-(r)**2)/(k))\n",
    "    return(w)\n",
    "my_weight_func = partial(barnes, k=k)\n",
    "obanAnalysis, obanAnalysisWeight  = oban(points,refTrue,xi,my_weight_func,search_radius)\n",
    "refinterpBarnes = interpolate_to_points(theStack, refTrue, theStack2, interp_type = 'barnes')\n",
    "print(obanAnalysis)\n",
    "def BackTo2D(refinterpLinear):\n",
    "    num_rows = 100\n",
    "    num_elements_per_row = len(refinterpLinear) // num_rows\n",
    "    refinterpLinear2D = refinterpLinear[:num_elements_per_row * num_rows].reshape(num_rows, num_elements_per_row)\n",
    "    return(refinterpLinear2D)\n",
    "\n",
    "obanAnalysis2D = BackTo2D(obanAnalysis)\n",
    "refinterpBarnes2D = BackTo2D(refinterpBarnes)\n",
    "obanInterpDiff = obanAnalysis2D - refinterpBarnes2D\n",
    "\n",
    "fig = plt.figure()\n",
    "n_rows,n_cols = 2,2,\n",
    "fig,axes = plt.subplots(n_rows, n_cols, figsize=(20,20))\n",
    "axes[0,0].plot\n",
    "axes[0,0].set_xlabel('x (m)')\n",
    "axes[0,0].set_ylabel('z (m)')\n",
    "axes[0,0].set_title('Reflectivity (Oban Analysis)')\n",
    "refplotter = axes[0,0].pcolormesh(rangearray, altarray, obanAnalysis2D, cmap='gist_ncar', vmin=-30, vmax=10)\n",
    "plt.colorbar(refplotter)\n",
    "\n",
    "\n",
    "axes[0,1].plot\n",
    "axes[0,1].set_xlabel('x (m)')\n",
    "axes[0,1].set_ylabel('z (m)')\n",
    "axes[0,1].set_title('Reflectivity (Interp to Points Analysis)')\n",
    "veloplotter = axes[0,1].pcolormesh(rangearray, altarray, refinterpBarnes2D, cmap='gist_ncar', vmin=-30, vmax=10)\n",
    "plt.colorbar(veloplotter)\n",
    "\n",
    "axes[1,0].plot\n",
    "axes[1,0].set_xlabel('x (m)')\n",
    "axes[1,0].set_ylabel('z (m)')\n",
    "axes[1,0].set_title('Reflectivity (Difference between oban and interp)')\n",
    "SWidthplotter = axes[1,0].pcolormesh(rangearray, altarray, obanInterpDiff, cmap='gist_ncar', vmin=-10, vmax=10)\n",
    "plt.colorbar(SWidthplotter)\n",
    "\n",
    "axes[1,1].plot\n",
    "axes[1,1].set_xlabel('x (m)')\n",
    "axes[1,1].set_ylabel('z (m)')\n",
    "axes[1,1].set_title('Uninterpolated Reflectivity')\n",
    "Powerplotter = axes[1,1].pcolormesh(x, z, ref.data, cmap='gist_ncar', vmin=-30, vmax=10)\n",
    "axes[1, 1].set_xlim(9000, 9500)\n",
    "axes[1, 1].set_ylim(2900, 3400)\n",
    "plt.colorbar(Powerplotter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.** Let's say we want to use another filter from [Harris (1978)](https://ieeexplore.ieee.org/iel5/5/31261/01455106.pdf?casa_token=nY_Vus-tiGQAAAAA:1K1Z17V0-r1wCpI7TlY0OFKZGTTtigj1xTtyLAj_DEkaAVYnkDVUh7Kl0BLFJjQZ4647zYZJm4c-) for our continuous data. Those functions are specified for discrete data, with a hard cutoff after $N$ samples. It would be logical to cut off all our analyses after the same cutoff radius for all data, so that our understanding of the filter function sidelobe behavior from discrete theory can be applied to continous data in an even-handed way.\n",
    "\n",
    "So, let's repeat the previous question, but now using the Rectangular and Blackman-Harris weights. You will need to use Harris (1978) for the mathematical formulation of the windows, as defined below.\n",
    "\n",
    "**a.**  Implement a `rect` function and then use it with `oban` to calculate an analysis on the target grid.\n",
    "\n",
    "**b.**  Implement a `blackman_harris` function and then use it with `oban` to calculate an analysis on the target grid. Use the minimum 4-term Blackman-Harris formulation as in the `scipy.signal.blackmanharris` docs whose coefficients are the -92 dB 4-term window in the table on p. 65 of Harris.\n",
    "\n",
    "**c.**  Include in this notebook, using a Markdown cell and the $\\LaTeX$ functionality, a narrated derivation that shows how you converted the discrete, non-dimensional formulation of the Blackman-Harris weight function to a continuous, dimensional form.\n",
    "\n",
    "**d.**  Make a plot of the weight functions as a function of distance from zero to your cutoff radius.\n",
    "\n",
    "**e.**  Plot the original data and the two analyses.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def useless(r):\n",
    "    rect = np.ones_like(r)\n",
    "    return rect\n",
    "my_weight_func = partial(useless)\n",
    "obanAnalysisRect, weightObanRect = oban(points,refTrue,xi,my_weight_func,search_radius)\n",
    "\n",
    "\n",
    "def blackman(n, N):\n",
    "    a0 = 0.35875\n",
    "    a1 = 0.48829\n",
    "    a2 = 0.14128\n",
    "    a3 = 0.01168\n",
    "    w = (a0 \n",
    "        - ( a1 * np.cos( ((2*(np.pi))/N) * (n+(N/2)) ))\n",
    "        + (a2*np.cos(((2*(np.pi))/N)*(2*(n+(N/2)))))\n",
    "        - (a3*np.cos(((2*(np.pi))/N)*(3*(n+(N/2))))))\n",
    "    return w\n",
    "\n",
    "my_weight_func = partial(blackman, N=search_radius)\n",
    "obanAnalysisBlackman, weightObanBlackman = oban(points,refTrue,xi,my_weight_func,search_radius)\n",
    "obanAnalysisRect2D = BackTo2D(obanAnalysisRect)\n",
    "obanAnalysisBlackman2D = BackTo2D(obanAnalysisBlackman)\n",
    "fig = plt.figure()\n",
    "n_rows, n_cols = 2, 2\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, 20))\n",
    "\n",
    "axes[0, 0].set_xlabel('x (m)')\n",
    "axes[0, 0].set_ylabel('z (m)')\n",
    "axes[0, 0].set_title('Reflectivity (Oban Analysis)')\n",
    "refplotter = axes[0, 0].pcolormesh(rangearray, altarray, obanAnalysis2D, cmap='gist_ncar', vmin=-30, vmax=10)\n",
    "plt.colorbar(refplotter)\n",
    "\n",
    "\n",
    "\n",
    "axes[0, 1].set_xlabel('x (m)')\n",
    "axes[0, 1].set_ylabel('z (m)')\n",
    "axes[0, 1].set_title('Reflectivity (Rect)')\n",
    "SWidthplotter = axes[0, 1].pcolormesh(rangearray, altarray, obanAnalysisRect2D, cmap='gist_ncar', vmin=-30, vmax=10)\n",
    "plt.colorbar(SWidthplotter)\n",
    "\n",
    "axes[1, 0].set_xlabel('x (m)')\n",
    "axes[1, 0].set_ylabel('z (m)')\n",
    "axes[1, 0].set_title('Reflectivity (Blackman)')\n",
    "Powerplotter = axes[1, 0].pcolormesh(rangearray, altarray, obanAnalysisBlackman2D, cmap='gist_ncar', vmin=-30, vmax=10)\n",
    "axes[1, 0].set_xlim(9000, 9500)\n",
    "axes[1, 0].set_ylim(2900, 3400)\n",
    "plt.colorbar(Powerplotter)\n",
    "\n",
    "axes[1, 1].set_xlabel('x (m)')\n",
    "axes[1, 1].set_ylabel('z (m)')\n",
    "axes[1, 1].set_title('Uninterpolated Reflectivity')\n",
    "Uninterpplotter = axes[1, 1].pcolormesh(x, z, ref.data, cmap='gist_ncar', vmin=-30, vmax=10)  # Replace with your data array\n",
    "axes[1, 1].set_xlim(9000, 9500)\n",
    "axes[1, 1].set_ylim(2900, 3400)\n",
    "plt.colorbar(Uninterpplotter)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fake_array = np.linspace(0, search_radius, 100)\n",
    "weightBlackman = blackman(fake_array, search_radius)\n",
    "\n",
    "# Create a new figure and subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Plot weightBlackman\n",
    "axes[0].plot(fake_array, weightBlackman, label='Blackman')\n",
    "axes[0].set_title('Weight - Blackman')\n",
    "axes[0].set_xlabel('r')\n",
    "axes[0].set_ylabel('Weight')\n",
    "axes[0].legend()\n",
    "\n",
    "# Plot weightObanRect\n",
    "axes[1].plot(weightObanRect, label='Oban Rect')\n",
    "axes[1].set_title('Weight - Oban Rect')\n",
    "axes[1].set_xlabel('r')\n",
    "axes[1].set_ylabel('Weight')\n",
    "axes[1].legend()\n",
    "\n",
    "# Adjust layout for better spacing\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In order to convert the formula:\n",
    "$\n",
    "\\newline\n",
    "[ W_{\\text{BH}}(r, N) = a_0 - a_1 \\cos\\left(\\frac{2\\pi}{N} r\\right) + a_2 \\cos\\left(\\frac{4\\pi}{N} r\\right) - a_3 \\cos\\left(\\frac{6\\pi}{N} r\\right) ]\n",
    "\\newline\n",
    "$\n",
    "to a continuous and discrete form, I phase-shifted it by $( \\frac{N}{2} )$ and ended up with this equation:\n",
    "$\n",
    "\\newline\n",
    "[ W_{\\text{BH}}(n, N) = a_0 - a_1 \\cos\\left(\\frac{2\\pi}{N} (n + \\frac{N}{2})\\right) + a_2 \\cos\\left(\\frac{4\\pi}{N} (n + \\frac{N}{2})\\right) - a_3 \\cos\\left(\\frac{6\\pi}{N} (n + \\frac{N}{2})\\right) ]\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**5.** Let's compare the different filters.\n",
    "\n",
    "**a.** Plot the original data, and using the Barnes filter as a common point of comparison, plot the difference with the other two analyses you calculated.\n",
    "\n",
    "**b.** Which weighting scheme preserves the greatest detail in fine-scale structure? Illustrate this by discussing a local minimum and a local maximum in the original data vs. the difference fields. Does it make sense in terms of the theoretical response functions we calcualted in the previous homework?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "n_rows, n_cols = 3, 1\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(10, 20))\n",
    "\n",
    "obanRectDiff = obanAnalysisRect2D - refinterpBarnes2D\n",
    "obanBlackmanDiff = obanAnalysisBlackman2D - refinterpBarnes2D\n",
    "\n",
    "\n",
    "axes[0].set_xlabel('x (m)')\n",
    "axes[0].set_ylabel('z (m)')\n",
    "axes[0].set_title('Uninterpolated Reflectivity')\n",
    "Uninterpplotter = axes[0].pcolormesh(x, z, ref.data, cmap='gist_ncar', vmin=-30, vmax=10)  # Replace with your data array\n",
    "axes[0].set_xlim(9000, 9500)\n",
    "axes[0].set_ylim(2900, 3400)\n",
    "plt.colorbar(Uninterpplotter)\n",
    "\n",
    "\n",
    "axes[1].set_xlabel('x (m)')\n",
    "axes[1].set_ylabel('z (m)')\n",
    "axes[1].set_title('Rect-Barnes Difference')\n",
    "obanRectDiffPlot = axes[1].pcolormesh(rangearray, altarray, obanRectDiff, cmap='gist_ncar', vmin=-10, vmax=10)  # Replace with your data array\n",
    "axes[1].set_xlim(9000, 9500)\n",
    "axes[1].set_ylim(2900, 3400)\n",
    "plt.colorbar(obanRectDiffPlot)\n",
    "\n",
    "\n",
    "axes[2].set_xlabel('x (m)')\n",
    "axes[2].set_ylabel('z (m)')\n",
    "axes[2].set_title('Blackman Harris-Barnes Difference')\n",
    "obanBlackmanDiffPlot = axes[2].pcolormesh(rangearray, altarray, obanBlackmanDiff, cmap='gist_ncar', vmin=-10, vmax=10)  # Replace with your data array\n",
    "axes[2].set_xlim(9000, 9500)\n",
    "axes[2].set_ylim(2900, 3400)\n",
    "plt.colorbar(obanBlackmanDiffPlot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "print('The weighting function that preserves the most fine scale detail is absolutely Blackman-Harris. In almost every patch in the difference plot you cans ee where the Rect is significantly smoother than the Blackman Harris. In order to point this out at one point specifically, I would focus in the top right, where rect significantly smooths over some of the lower reflectivity values and Blackman Harris still resolves streaks of reflectivity. Yes this is exactly the result we would expect based on our response functions from the previous homework, where Blackman Harris outperformed other filters.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
