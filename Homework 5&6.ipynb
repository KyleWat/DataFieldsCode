{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "  span.ecb { background: yellow; }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style type=\"text/css\">\n",
    "  span.ecb { background: yellow; }\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from functools import partial\n",
    "from scipy.spatial import cKDTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ATMO 5331 - Homework 5 & 6 - Fall 2023\n",
    "## Due **Thursday** 30 Nov, 2023, 11:59 pm.\n",
    "## *Worth two assignments*\n",
    "\n",
    "When doing this homework, remember that you have two jobs:\n",
    "1. Make it work.\n",
    "2. Clean it up so that I can understand what you've done. If you think I might not understand, document it with a comment or a function docstring.\n",
    "\n",
    "You should present your work with a clear logical progression. If that seems like a hassle, remember that in doing so you are practicing skills that are expected in your thesis and journal publications.\n",
    "\n",
    "You may work alone or in pairs. I will not be adjudicating relative level of effort in group work, so you are responsible for ensuring that you and your partner contribute equally.\n",
    "\n",
    "<span class=\"ecb\">Comments by ECB</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.** Copy in your setup from HW3, so that you have the radar data, radar locations, and analysis grid available. Use only the tangent plane cartesian system part, and you don't need to include the plots. Take the time to clean up your original code so that it's the minimally necessary set of variables and functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.** Configuration of the weighting scheme requires that we know the typical data spacing. Following [TD2000](https://journals.ametsoc.org/view/journals/atot/17/2/1520-0426_2000_017_0105_rdoa_2_0_co_2.xml?tab_body=fulltext-display), define the data spacing as the distance betweent two radar gates at the maximum range. Use the point in your analysis grid that is farthest from the radar, and then find the maximum spacing in elevation angle at this range. Finally, calculate the difference in linear units between the two radar gates you idenified.\n",
    "\n",
    "Please provide an answer to these two questions:\n",
    "- What is the maximum distance from the radar in the objective analysis domain?\n",
    "- What is the maximum spacing between two adjacent data points?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.** Below, the function `oban` (for \"objective analysis\") mimics the call signature of the MetPy `interpolate_to_points` function. Its principal difference is the `weight_func` argument, which takes a function instead of a string describing an interpolation method. \n",
    "\n",
    "The `oban` function passes `weight_func` only the distances, so it is necessary to use `partial` to pre-fill the function with any other arguments needed to configure the weight function. The `sample_weights` function below shows how this works.\n",
    "\n",
    "For fun, I've also included a seasonal illustration of the use of `partial`.\n",
    "\n",
    "For this question, your jobs are as follows.\n",
    "\n",
    "**a.**  Specify a cutoff radius. Based on the last homework assignment, what is a good distance to use as a multiple of the data spacing? Make sure to adjust your set of input data points to include the necessary margin beyond the perimeter of the analysis grid.\n",
    "\n",
    "**b.**  Implement a `barnes` function and then use it with `oban` to calculate an analysis for reflectivity on the target grid.  Note that you will need to complete the `oban` function in a way that will work with any weight function.\n",
    "\n",
    "**c.**  Calculate a Barnes analysis using MetPy, as in the last assignment, and find the difference (yours - MetPy). They probably won't be the same, even for a sane configuration of parameters; that's ok.\n",
    "\n",
    "**d.**  Plot the original data, the two analyses, and the difference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def thanksgiving(holiday_question, pie=False):\n",
    "    print(holiday_question, \"pie?\", pie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On this day will I eat pie? True\n"
     ]
    }
   ],
   "source": [
    "thanksgiving(\"On this day will I eat\", pie=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bad_thanksgiving = partial(thanksgiving, \"On this day I will eat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On this day I will eat pie? No, because none were made for me.\n"
     ]
    }
   ],
   "source": [
    "bad_thanksgiving(\"No, because none were made for me.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3. 3. 3. 3. 3. 3. 3. 3. 3. 3.]\n"
     ]
    }
   ],
   "source": [
    "def oban(points, values, xi, weight_func, search_radius):\n",
    "    \"\"\"\n",
    "    points: N,2 data point locations\n",
    "    values: N data values\n",
    "    xi: M,2 analysis locations\n",
    "    weight_func is a function that accepts a single argument r that is the\n",
    "        distance between the analysis location and all points within search_radius\n",
    "        of the analysis location.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Find all points in the vicinity of each analysis location in xi\n",
    "    tree = cKDTree(points)\n",
    "    query = tree.query_ball_point(xi, search_radius)\n",
    "    \n",
    "    analysis = np.zeros(xi.shape[0])\n",
    "    \n",
    "    # This is linear (times the typical neighborhood size) in the number of analysis points\n",
    "    for i, (analysis_point, neighbors) in enumerate(zip(xi, query)):\n",
    "        data = values[neighbors]\n",
    "        data_locations = points[neighbors,:]\n",
    "        # use data, data_locations, analysis_point, and weight_func to fill in the rest of the analysis\n",
    "        analysis[i] = None # your code here\n",
    "    return analysis\n",
    "\n",
    "def sample_weights(r, value=None):\n",
    "    return np.zeros_like(r) + value\n",
    "\n",
    "my_weight_func = partial(sample_weights, value=3.0)\n",
    "my_test_ranges = np.arange(10.0)\n",
    "my_test_weights = my_weight_func(my_test_ranges) # oban will call my_weight_func like so\n",
    "print(my_test_weights) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.** Let's say we want to use another filter from [Harris (1978)](https://ieeexplore.ieee.org/iel5/5/31261/01455106.pdf?casa_token=nY_Vus-tiGQAAAAA:1K1Z17V0-r1wCpI7TlY0OFKZGTTtigj1xTtyLAj_DEkaAVYnkDVUh7Kl0BLFJjQZ4647zYZJm4c-) for our continuous data. Those functions are specified for discrete data, with a hard cutoff after $N$ samples. It would be logical to cut off all our analyses after the same cutoff radius for all data, so that our understanding of the filter function sidelobe behavior from discrete theory can be applied to continous data in an even-handed way.\n",
    "\n",
    "So, let's repeat the previous question, but now using the Rectangular and Blackman-Harris weights. You will need to use Harris (1978) for the mathematical formulation of the windows, as defined below.\n",
    "\n",
    "**a.**  Implement a `rect` function and then use it with `oban` to calculate an analysis on the target grid.\n",
    "\n",
    "**b.**  Implement a `blackman_harris` function and then use it with `oban` to calculate an analysis on the target grid. Use the minimum 4-term Blackman-Harris formulation as in the `scipy.signal.blackmanharris` docs whose coefficients are the -92 dB 4-term window in the table on p. 65 of Harris.\n",
    "\n",
    "**c.**  Include in this notebook, using a Markdown cell and the $\\LaTeX$ functionality, a narrated derivation that shows how you converted the discrete, non-dimensional formulation of the Blackman-Harris weight function to a continuous, dimensional form.\n",
    "\n",
    "**d.**  Make a plot of the weight functions as a function of distance from zero to your cutoff radius.\n",
    "\n",
    "**e.**  Plot the original data and the two analyses.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.** Let's compare the different filters.\n",
    "\n",
    "**a.** Plot the original data, and using the Barnes filter as a common point of comparison, plot the difference with the other two analyses you calculated.\n",
    "\n",
    "**b.** Which weighting scheme preserves the greatest detail in fine-scale structure? Illustrate this by discussing a local minimum and a local maximum in the original data vs. the difference fields. Does it make sense in terms of the theoretical response functions we calcualted in the previous homework?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:atmo5331]",
   "language": "python",
   "name": "conda-env-atmo5331-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
